{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18cfbff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.special import expit\n",
    "from numpy.random import permutation\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83bfd8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('../../data/regression/square-simple-training.csv', index_col = 0)\n",
    "data_test = pd.read_csv('../../data/regression/square-simple-test.csv', index_col = 0)\n",
    "x = data_train[['x']]\n",
    "y = data_train[['y']]\n",
    "x_test = data_test[['x']]\n",
    "y_test = data_test[['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a31d6574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): #stablina numerycznie\n",
    "    return expit(x)\n",
    "\n",
    "def linear(x):\n",
    "    # Liniowa funkcja aktywacji f(x) = x\n",
    "    return x\n",
    "\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    \"\"\"Pochodna funkcji aktywacji sigmoidalnej\"\"\"\n",
    "    return sigmoid(z) * (1 - sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43483bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedforward (x, weights, biases, sizes):   \n",
    "    # Propagacja do przodu\n",
    "    # activations to lista aktywacji dla każdej warstwy, zaczynając od warstwy wejściowej i kończąc na warstwie wyjściowej.\n",
    "    # na pierwszym obrocie to x bez funkcji aktywacji, czyli dane wejściowe\n",
    "    activations = [x]\n",
    "    # zs to lista wartości (sumy ważone plus biasy) dla każdej warstwy, zaczynając od warstwy ukrytej i kończąc na warstwie wyjściowej.\n",
    "    zs = []\n",
    "    for j in range(len(sizes)-1):\n",
    "        z = np.dot(activations[-1], weights[j]) + biases[j]\n",
    "#             print('zzzzzzzzzzzzzzzzzzzz')\n",
    "#             print(z)\n",
    "        zs.append(z)\n",
    "        if j == len(sizes)-2:\n",
    "            # Dla ostatniej warstwy używamy liniowej funkcji aktywacji\n",
    "            activation = linear(z)\n",
    "        else:\n",
    "            # Dla pozostałych warstw używamy funkcji aktywacji sigmoid\n",
    "            activation = sigmoid(z)\n",
    "#             print('aaaaaaaaaaaa')\n",
    "#             print(activation)\n",
    "        activations.append(activation)\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ee80e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(y, activations, errors, sizes, weights, biases):\n",
    "    # Obliczenie błędu w warstwie wyjściowej\n",
    "    error = y - activations[-1]\n",
    "    errors.append(np.mean(error**2))\n",
    "\n",
    "    # Propagacja wsteczna\n",
    "    delta = error * sigmoid_prime(activations[-1])\n",
    "    deltas = [delta]\n",
    "    for j in range(2, len(sizes)):\n",
    "        #print(deltas)\n",
    "        delta = np.dot(delta, weights[-j+1].T) * sigmoid_prime(activations[-j])\n",
    "        deltas.append(delta)\n",
    "    deltas.reverse()\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e9a5fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights_biases(deltas, weights, biases, learning_rate, activations):\n",
    "    # Aktualizacja wag i biasów\n",
    "    for j in range(len(weights)):\n",
    "        weights[j] -= learning_rate * np.dot(activations[j].T, deltas[j])\n",
    "        biases[j] -= learning_rate * np.mean(deltas[j], axis=0)\n",
    "    return weights, biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d820a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, y, sizes, epochs, learning_rate):\n",
    "    \"\"\"\n",
    "    Funkcja wykonująca algorytm wstecznej propagacji błędu dla wielowarstwowej sieci neuronowej.\n",
    "\n",
    "    Argumenty:\n",
    "    x: macierz danych wejściowych (num_examples, num_features)\n",
    "    y: macierz danych wyjściowych (num_examples, num_outputs)\n",
    "    sizes: lista zawierająca liczbę neuronów w każdej warstwie (w tym liczba neuronów w warstwie wejściowej i wyjściowej)\n",
    "    epochs: liczba epok\n",
    "    learning_rate: współczynnik uczenia\n",
    "\n",
    "    Zwraca:\n",
    "    Tuple:\n",
    "    - macierz wag nauczonych\n",
    "    - wektor biasów nauczonych\n",
    "    - wektor błędów dla każdej epoki\n",
    "\n",
    "    \"\"\"\n",
    "    # Inicjalizacja wag i biasów dla każdej warstwy\n",
    "    weights = [np.random.randn(sizes[i-1], sizes[i]) / np.sqrt(sizes[i-1]) for i in range(1, len(sizes))]\n",
    "    biases = [np.zeros((1, sizes[i])) for i in range(1, len(sizes))]\n",
    "    # Lista przechowująca błędy dla każdej epoki\n",
    "    errors = []\n",
    "    for i in range(epochs):  \n",
    "        activations = feedforward(x, weights, biases, sizes)\n",
    "        deltas = backpropagation(y, activations, errors, sizes, weights, biases)\n",
    "        weights, biases = update_weights_biases(deltas, weights, biases, learning_rate, activations)\n",
    "        \n",
    "    return weights, biases, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ef1be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases, errors = mlp(x, y, [1, 5, 1], 300, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbee39f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2894fe258b0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, len(errors)), errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation_MLP(x, y, sizes, epochs, learning_rate):\n",
    "    \"\"\"\n",
    "    Funkcja wykonująca algorytm wstecznej propagacji błędu dla wielowarstwowej sieci neuronowej.\n",
    "\n",
    "    Argumenty:\n",
    "    x: macierz danych wejściowych (num_examples, num_features)\n",
    "    y: macierz danych wyjściowych (num_examples, num_outputs)\n",
    "    sizes: lista zawierająca liczbę neuronów w każdej warstwie (w tym liczba neuronów w warstwie wejściowej i wyjściowej)\n",
    "    epochs: liczba epok\n",
    "    learning_rate: współczynnik uczenia\n",
    "\n",
    "    Zwraca:\n",
    "    Tuple:\n",
    "    - macierz wag nauczonych\n",
    "    - wektor biasów nauczonych\n",
    "    - wektor błędów dla każdej epoki\n",
    "\n",
    "    \"\"\"\n",
    "    # Inicjalizacja wag i biasów dla każdej warstwy\n",
    "    weights = [np.random.randn(sizes[i-1], sizes[i]) / np.sqrt(sizes[i-1]) for i in range(1, len(sizes))]\n",
    "    biases = [np.zeros((1, sizes[i])) for i in range(1, len(sizes))]\n",
    "\n",
    "    # Lista przechowująca błędy dla każdej epoki\n",
    "    errors = []\n",
    "\n",
    "    for i in range(epochs):        \n",
    "        # Propagacja do przodu\n",
    "        # activations to lista aktywacji dla każdej warstwy, zaczynając od warstwy wejściowej i kończąc na warstwie wyjściowej.\n",
    "        # na pierwszym obrocie to x bez funkcji aktywacji, czyli dane wejściowe\n",
    "        activations = [x]\n",
    "        # zs to lista wartości (sumy ważone plus biasy) dla każdej warstwy, zaczynając od warstwy ukrytej i kończąc na warstwie wyjściowej.\n",
    "        zs = []\n",
    "        for j in range(len(sizes)-1):\n",
    "            z = np.dot(activations[-1], weights[j]) + biases[j]\n",
    "#             print('zzzzzzzzzzzzzzzzzzzz')\n",
    "#             print(z)\n",
    "            zs.append(z)\n",
    "            if j == len(sizes)-2:\n",
    "                # Dla ostatniej warstwy używamy liniowej funkcji aktywacji\n",
    "                activation = linear(z)\n",
    "            else:\n",
    "                # Dla pozostałych warstw używamy funkcji aktywacji sigmoid\n",
    "                activation = sigmoid(z)\n",
    "#             print('aaaaaaaaaaaa')\n",
    "#             print(activation)\n",
    "            activations.append(activation)\n",
    "\n",
    "        # Obliczenie błędu w warstwie wyjściowej\n",
    "        error = y - activations[-1]\n",
    "        errors.append(np.mean(error**2))\n",
    "\n",
    "        # Propagacja wsteczna\n",
    "        delta = error * sigmoid_prime(activations[-1])\n",
    "        deltas = [delta]\n",
    "        for j in range(2, len(sizes)):\n",
    "            #print(deltas)\n",
    "            delta = np.dot(delta, weights[-j+1].T) * sigmoid_prime(activations[-j])\n",
    "            deltas.append(delta)\n",
    "        deltas.reverse()\n",
    "\n",
    "        # Aktualizacja wag i biasów\n",
    "        for j in range(len(weights)):\n",
    "            weights[j] -= learning_rate * np.dot(activations[j].T, deltas[j])\n",
    "            #biases[j] -= learning_rate * np.mean(deltas[j], axis=0)\n",
    "\n",
    "    return weights, biases, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b46668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backpropagation_MLP(x, y, [1, 5, 1], 500, 0.01)\n",
    "weights, biases, errors = backpropagation_MLP(x, y, [1, 5, 1], 500, 0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25e48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0, len(errors)), errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57704a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf01eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x, activations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51dcdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f97ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [1, 5, 1]\n",
    "weights = [np.random.randn(sizes[i-1], sizes[i]) / np.sqrt(sizes[i-1]) for i in range(1, len(sizes))]\n",
    "biases = [np.zeros((1, sizes[i])) for i in range(1, len(sizes))]\n",
    "errors = []\n",
    "activations = [x]\n",
    "zs = []\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e433b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = [x]\n",
    "zs = []\n",
    "for j in range(len(sizes)-1):\n",
    "    print(j)\n",
    "    # ostatni element z listy activations to wartości po zastosowaniu funkcji aktywacji do sumy ważonej neuronów w poprzedniej warstwie\n",
    "    # na pierwszym obrocie to x bez funkcji aktywacji, czyli dane wejściowe\n",
    "    z = np.dot(activations[-1], weights[j]) + biases[j]\n",
    "    zs.append(z)\n",
    "    if j == len(sizes)-2:\n",
    "        # Dla ostatniej warstwy używamy liniowej funkcji aktywacji\n",
    "        activation = linear(z)\n",
    "    else:\n",
    "        # Dla pozostałych warstw używamy funkcji aktywacji sigmoid\n",
    "        activation = sigmoid(z)\n",
    "    activations.append(activation)\n",
    "\n",
    "# Obliczenie błędu w warstwie wyjściowej\n",
    "#activations[-1].columns = ['y']\n",
    "error = y - activations[-1]\n",
    "errors.append(np.mean(error**2))\n",
    "\n",
    "# Propagacja wsteczna\n",
    "delta = error * sigmoid_prime(activations[-1])\n",
    "deltas = [delta]\n",
    "for j in range(2, len(sizes)-1):\n",
    "    delta = np.dot(delta, weights[-j+1].T) * sigmoid_prime(activations[-j])\n",
    "    deltas.append(delta)\n",
    "deltas.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1e300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(weights)):\n",
    "    weights[j] += learning_rate * np.dot(activations[j].T, deltas[j])\n",
    "    biases[j] += learning_rate * np.mean(deltas[j], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7d680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
